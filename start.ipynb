{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src') \n",
    "import os\n",
    "import json\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tot.methods.bfs import solve\n",
    "from tot.tasks.bio_name import Bio_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = argparse.Namespace(backend='gpt-4-1106-preview', temperature=0.7, task='bio_name', naive_run=False, prompt_sample=None, method_generate='sample_bionames', method_evaluate='votes_for_bionames', method_select='greedy', n_generate_sample=3, n_evaluate_sample=2, n_select_sample=2)\n",
    "args = argparse.Namespace(backend='gpt-3.5-turbo-1106', temperature=0.7, task='bio_name', naive_run=False, prompt_sample=None, method_generate='sample_bionames', method_evaluate='votes_for_bionames', method_select='greedy', n_generate_sample=3, n_evaluate_sample=2, n_select_sample=2)\n",
    "task = Bio_Name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# filename = 'src/tot/data/gene_sets/gene_sets.csv'\n",
    "# df = pd.read_csv(filename, header=None, encoding='latin1')\n",
    "# df.dropna(inplace=True)\n",
    "# df.columns = ['_', '_', 'genes', 'count', 'process']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df['genes'].tolist()\n",
    "# y = df['process'].tolist()\n",
    "# with open('src/tot/data/gene_sets/x.txt', 'w') as f:\n",
    "#     for el in x:\n",
    "#         f.write(el + '\\n')\n",
    "        \n",
    "# with open('src/tot/data/gene_sets/y.txt', 'w') as f:\n",
    "#     for el in y:\n",
    "#         f.write(el + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SapBERT_tokenizer = AutoTokenizer.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n",
    "SapBERT_model = AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceEmbedding(sentence, tokenizer, model):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        \n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceSimilarity(sentence1, sentence2, tokenizer, model, simMetric):\n",
    "    sentence1_embedding = getSentenceEmbedding(sentence1, tokenizer, model)\n",
    "    sentence2_embedding = getSentenceEmbedding(sentence2, tokenizer, model)\n",
    "    \n",
    "    if simMetric == \"cosine_similarity\":\n",
    "        sentenceSim = cosine_similarity(sentence1_embedding, sentence2_embedding)[0][0]\n",
    "    # ToDo: add other simMetrics\n",
    "    #elif simMetric == \"cosine_similarity_primitive\": # use primitive operations\n",
    "   #     sentenceSim = np.dot(sentence1_embedding, sentence2_embedding)/(norm(sentence1_embedding)*norm(sentence2_embedding))\n",
    "    \n",
    "    return sentenceSim, sentence1_embedding, sentence2_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(x, y):\n",
    "    return getSentenceSimilarity(x, y, SapBERT_tokenizer, SapBERT_model, \"cosine_similarity\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all process names:  12174\n",
      "Length of all process names:  12174\n"
     ]
    }
   ],
   "source": [
    "def get_all_labels():\n",
    "    all_process_names = []\n",
    "    for idx in range(12174):\n",
    "        label = task.get_label(idx)\n",
    "        all_process_names.append(label)\n",
    "    print('Length of all process names: ', len(all_process_names))\n",
    "    all_process_names = list(set(all_process_names))\n",
    "    print('Length of all process names: ', len(all_process_names))\n",
    "    return all_process_names\n",
    "\n",
    "all_labels = get_all_labels()\n",
    "\n",
    "import random\n",
    "def similarity_quantile(candidate, y):\n",
    "    scores = []\n",
    "    test_labels = random.sample(all_labels, 100)\n",
    "    for label in test_labels:\n",
    "        if label != y:\n",
    "            scores.append(similarity_score(label, y))\n",
    "    scores = np.array(scores)\n",
    "    candidate_score = similarity_score(candidate, y)\n",
    "    # return the fraction of scores that are smaller than the candidate\n",
    "    return (scores < candidate_score).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_example(args, task, idx):\n",
    "    label = task.get_label(idx)\n",
    "    final_answer, ys, steps = solve(args, task, idx)\n",
    "    return final_answer, ys, steps, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_candidate_bio_processes(steps):\n",
    "    candidate_processes = []\n",
    "    step_count = 0\n",
    "    for step in steps['steps'][:-1]:\n",
    "        step_count += 1\n",
    "        new_ys = [json.loads(step['new_ys'][i]) for i in range(len(step['new_ys']))]\n",
    "        new_bio_processes = [y['Biological Process'] for y in new_ys]\n",
    "        candidate_processes.extend(new_bio_processes)\n",
    "    candidate_processes = list(set(candidate_processes))\n",
    "    return candidate_processes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_candidate_bio_process(candidate_processes, label):\n",
    "    scores = [similarity_score(candidate_process, label) for candidate_process in candidate_processes]\n",
    "    best_candidate_process = candidate_processes[np.argmax(scores)]\n",
    "    return best_candidate_process, np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tot.models import *\n",
    "gpt = partial(gpt, model=args.backend, temperature=args.temperature)\n",
    "def get_gpt_similarity_score(process1, process2):\n",
    "    system_message, user_message = task.similarity_prompt_wrap(process1, process2)\n",
    "    response = gpt(system_message, user_message)\n",
    "    similarity_score = task.unwrap_similarity(response)\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_example_wrap(idx):\n",
    "    final_answer, ys, steps, label = test_example(args, task, idx)\n",
    "    candidate_processes = get_all_candidate_bio_processes(steps)\n",
    "    best_candidate_process, best_candidate_similarity_score = get_best_candidate_bio_process(candidate_processes, label)\n",
    "    final_answer_similarity_score = similarity_score(final_answer, label)\n",
    "    final_answer_gpt_similarity_score = get_gpt_similarity_score(final_answer, label)\n",
    "    final_answer_similarity_quantile = similarity_quantile(final_answer, label)\n",
    "    best_candidate_similarity_quantile = similarity_quantile(best_candidate_process, label)\n",
    "    print('Index:', idx)\n",
    "    print('Final answer:', final_answer)\n",
    "    print('True answer:', label.strip())\n",
    "    print('Final answer similarity score:', similarity_score(final_answer, label))\n",
    "    print('Best candidate process:', best_candidate_process)\n",
    "    print('Best candidate similarity score:', best_candidate_similarity_score)\n",
    "    print('GPT final answer similarity score:', final_answer_gpt_similarity_score)\n",
    "    print('GPT best candidate similarity score:', get_gpt_similarity_score(best_candidate_process, label))\n",
    "    print('Final Answer Similarity Quantile:', final_answer_similarity_quantile)\n",
    "    print('Best Candidate Similarity Quantile:', best_candidate_similarity_quantile)\n",
    "    print()\n",
    "    return {'index': idx, 'final answer': final_answer, 'ys': ys, 'steps': steps, 'label': label, 'final answer similarity score': final_answer_similarity_score,'best candidate process': best_candidate_process, 'best similarity score': best_candidate_similarity_score, 'GPT similarity score': final_answer_gpt_similarity_score,\n",
    "            'final answer similarity quantile': final_answer_similarity_quantile, 'best candidate similarity quantile': best_candidate_similarity_quantile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "print(similarity_quantile('Intrinsic Apoptotic Signaling Pathway', 'positive regulation of calcium ion transport into cytosol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Final answer: BAX-Mediated Permeabilization\n",
      "True answer: positive regulation of calcium ion transport into cytosol\n",
      "Final answer similarity score: 0.21824522\n",
      "Best candidate process: Calcium Ion Transport\n",
      "Best candidate similarity score: 0.7685968\n",
      "GPT final answer similarity score: 3\n",
      "GPT best candidate similarity score: 9\n",
      "Final Answer Similarity Quantile: 0.61\n",
      "Best Candidate Similarity Quantile: 1.0\n",
      "\n",
      "Index: 1\n",
      "Final answer: Fingertip Morphogenesis\n",
      "True answer: morphogenesis of an epithelial fold\n",
      "Final answer similarity score: 0.5714805\n",
      "Best candidate process: Apical Ectodermal Ridge (AER) Development\n",
      "Best candidate similarity score: 0.6691636\n",
      "GPT final answer similarity score: 9\n",
      "GPT best candidate similarity score: 9\n",
      "Final Answer Similarity Quantile: 0.99\n",
      "Best Candidate Similarity Quantile: 1.0\n",
      "\n",
      "Index: 2\n",
      "Final answer: RNA degradation in the cytoplasm\n",
      "True answer: U5 snRNA 3'-end processing\n",
      "Final answer similarity score: 0.45956868\n",
      "Best candidate process: Nuclear RNA processing\n",
      "Best candidate similarity score: 0.61757207\n",
      "GPT final answer similarity score: 3\n",
      "GPT best candidate similarity score: 8\n",
      "Final Answer Similarity Quantile: 0.99\n",
      "Best Candidate Similarity Quantile: 1.0\n",
      "\n",
      "Index: 3\n",
      "Final answer: AKAP12-mediated GPCR Signaling in Cardiovascular System\n",
      "True answer: regulation of oligodendrocyte apoptotic process\n",
      "Final answer similarity score: 0.2936181\n",
      "Best candidate process: Apoptosis Regulation via MAPK Signaling\n",
      "Best candidate similarity score: 0.5291198\n",
      "GPT final answer similarity score: 3\n",
      "GPT best candidate similarity score: 7\n",
      "Final Answer Similarity Quantile: 0.68\n",
      "Best Candidate Similarity Quantile: 1.0\n",
      "\n",
      "Index: 4\n",
      "Final answer: Beta-Oxidation\n",
      "True answer: circadian rhythm\n",
      "Final answer similarity score: 0.34905687\n",
      "Best candidate process: Circadian Rhythm Regulation\n",
      "Best candidate similarity score: 0.90975153\n",
      "GPT final answer similarity score: 3\n",
      "GPT best candidate similarity score: 9\n",
      "Final Answer Similarity Quantile: 0.82\n",
      "Best Candidate Similarity Quantile: 1.0\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'final_path' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(test_example_wrap(idx))\n",
      "\u001b[1;32m/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_example_wrap\u001b[39m(idx):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     final_answer, ys, steps, label \u001b[39m=\u001b[39m test_example(args, task, idx)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     candidate_processes \u001b[39m=\u001b[39m get_all_candidate_bio_processes(steps)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     best_candidate_process, best_candidate_similarity_score \u001b[39m=\u001b[39m get_best_candidate_bio_process(candidate_processes, label)\n",
      "\u001b[1;32m/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_example\u001b[39m(args, task, idx):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     label \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mget_label(idx)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     final_answer, ys, steps \u001b[39m=\u001b[39m solve(args, task, idx)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kylecox/Documents/ws/tot-gene-sets/start.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m final_answer, ys, steps, label\n",
      "File \u001b[0;32m~/Documents/ws/tot-gene-sets/src/tot/methods/bfs.py:285\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(args, task, idx, to_print)\u001b[0m\n\u001b[1;32m    282\u001b[0m         final_relation \u001b[39m=\u001b[39m relations[i]\n\u001b[1;32m    283\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m trie\u001b[39m.\u001b[39minsert(final_path, \u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m, final_relation)\n\u001b[1;32m    286\u001b[0m dot \u001b[39m=\u001b[39m trie\u001b[39m.\u001b[39mvisualize()\n\u001b[1;32m    287\u001b[0m dot\u001b[39m.\u001b[39mrender(\u001b[39m'\u001b[39m\u001b[39mviz/trie_visualization_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(idx), \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'final_path' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx in range(100, 110):\n",
    "    results.append(test_example_wrap(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_answer, ys, infos = solve(args, task, 0)\n",
    "# print(ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ys, infos = solve(args, task, 0)\n",
    "# print(ys[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

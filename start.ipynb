{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src') \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tot.methods.bfs import solve\n",
    "from tot.tasks.bio_name import Bio_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = argparse.Namespace(backend='gpt-4-1106-preview', temperature=0.7, task='bio_name', naive_run=False, prompt_sample=None, method_generate='sample_bionames', method_evaluate='votes_for_bionames', method_select='greedy', n_generate_sample=3, n_evaluate_sample=2, n_select_sample=2)\n",
    "args = argparse.Namespace(backend='gpt-3.5-turbo-1106', temperature=0.7, task='bio_name', naive_run=False, prompt_sample=None, method_generate='sample_bionames', method_evaluate='votes_for_bionames', method_select='greedy', n_generate_sample=3, n_evaluate_sample=2, n_select_sample=2)\n",
    "task = Bio_Name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# filename = 'src/tot/data/gene_sets/gene_sets.csv'\n",
    "# df = pd.read_csv(filename, header=None, encoding='latin1')\n",
    "# df.dropna(inplace=True)\n",
    "# df.columns = ['_', '_', 'genes', 'count', 'process']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df['genes'].tolist()\n",
    "# y = df['process'].tolist()\n",
    "# with open('src/tot/data/gene_sets/x.txt', 'w') as f:\n",
    "#     for el in x:\n",
    "#         f.write(el + '\\n')\n",
    "        \n",
    "# with open('src/tot/data/gene_sets/y.txt', 'w') as f:\n",
    "#     for el in y:\n",
    "#         f.write(el + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SapBERT_tokenizer = AutoTokenizer.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n",
    "SapBERT_model = AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceEmbedding(sentence, tokenizer, model):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        \n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceSimilarity(sentence1, sentence2, tokenizer, model, simMetric):\n",
    "    sentence1_embedding = getSentenceEmbedding(sentence1, tokenizer, model)\n",
    "    sentence2_embedding = getSentenceEmbedding(sentence2, tokenizer, model)\n",
    "    \n",
    "    if simMetric == \"cosine_similarity\":\n",
    "        sentenceSim = cosine_similarity(sentence1_embedding, sentence2_embedding)[0][0]\n",
    "    # ToDo: add other simMetrics\n",
    "    #elif simMetric == \"cosine_similarity_primitive\": # use primitive operations\n",
    "   #     sentenceSim = np.dot(sentence1_embedding, sentence2_embedding)/(norm(sentence1_embedding)*norm(sentence2_embedding))\n",
    "    \n",
    "    return sentenceSim, sentence1_embedding, sentence2_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(x, y):\n",
    "    return getSentenceSimilarity(x, y, SapBERT_tokenizer, SapBERT_model, \"cosine_similarity\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_example(args, task, idx):\n",
    "    y = task.get_label(idx)\n",
    "    print('Final answer:', y)\n",
    "    final_answer, _, _ = solve(args, task, idx)\n",
    "    print('Final answer:', final_answer)\n",
    "    print('True answer:', y)\n",
    "    print('Similarity score:', similarity_score(final_answer, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: circadian rhythm\n",
      "\n",
      "-- step 0 --\n",
      " -- select ids --\n",
      "[0, 1]\n",
      "-- paths --\n",
      "Gene Expression\n",
      "Cell Signaling\n",
      "Metabolic Pathways\n",
      "-- new_ys --: ['Gene Expression', 'Cell Signaling', 'Metabolic Pathways']\n",
      "-- sol values --: (1, 1, 0)\n",
      "-- choices --: ['Gene Expression', 'Cell Signaling']\n",
      "\n",
      "-- step 1 --\n",
      " -- select ids --\n",
      "[0, 3]\n",
      " -- select relations --\n",
      "[['', 'is a'], ['', 'is a']]\n",
      " -- omit relations --\n",
      "[['', 'part of'], ['', 'part of'], ['', 'regulates'], ['', 'part of']]\n",
      "-- paths --\n",
      "Gene Expression -> Transcription\n",
      "Gene Expression -> Translation\n",
      "Gene Expression -> RNA Splicing\n",
      "Cell Signaling -> G Protein-Coupled Receptor Signaling\n",
      "Cell Signaling -> Circadian Rhythm Signaling\n",
      "Cell Signaling -> Insulin Signaling Pathway\n",
      "-- new_ys --: ['Transcription', 'G Protein-Coupled Receptor Signaling', 'Translation', 'RNA Splicing', 'Circadian Rhythm Signaling', 'Insulin Signaling Pathway']\n",
      "-- sol values --: (1, 1, 0, 0, 0, 0)\n",
      "-- choices --: ['Transcription', 'G Protein-Coupled Receptor Signaling']\n",
      "\n",
      "-- Relations --\n",
      "['is a', 'is a']\n",
      " -- relations --\n",
      "[['', 'is a'], ['', 'is a']]\n",
      "Name: Transcription\n",
      "Reason: Transcription is a more specific process than gene expression. It specifically refers to the synthesis of RNA from a DNA template, which is the initial step in gene expression. Genes such as EP300, KAT5, and CREB1 are relevant to this process as they are involved in the regulation of transcription.\n",
      "Final answer: Transcription\n",
      "True answer: circadian rhythm\n",
      "\n",
      "Similarity score: 0.38626862\n"
     ]
    }
   ],
   "source": [
    "test_example(args, task, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_answer, ys, infos = solve(args, task, 0)\n",
    "# print(ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ys, infos = solve(args, task, 0)\n",
    "# print(ys[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

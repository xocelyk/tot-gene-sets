{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02746c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "genai.configure(api_key=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565732a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bb4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0888965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index: 0\n",
       "content {\n",
       "  parts {\n",
       "    text: \"The meaning of life is a deep philosophical question that has been pondered by humans for centuries. There is no one definitive answer to this question, as it is a personal and subjective matter. However, there are many different perspectives and beliefs about what the meaning of life might be.\\n\\nSome people believe that the meaning of life is to find happiness and fulfillment. They may focus on pursuing their passions, building relationships with loved ones, or making a positive impact on the world. Others believe that the meaning of life is to serve a higher purpose, such as following a religious or spiritual path, or making a difference in society. Still others believe that the meaning of life is simply to experience and appreciate the beauty and wonder of the world around us.\\n\\nUltimately, the meaning of life is something that each individual must discover for themselves. There is no right or wrong answer, and what is meaningful to one person may not be meaningful to another. However, by reflecting on our own values, beliefs, and experiences, we can come to a deeper understanding of what makes our lives meaningful.\\n\\nHere are some common perspectives on the meaning of life:\\n\\n* **Happiness and fulfillment:** Many people believe that the meaning of life is to find happiness and fulfillment. This can be achieved through a variety of means, such as pursuing our passions, building relationships with loved ones, or making a positive impact on the world.\\n* **Service to others:** Some people believe that the meaning of life is to serve a higher purpose, such as following a religious or spiritual path, or making a difference in society. This can be done through volunteering, donating to charity, or simply being kind and helpful to others.\\n* **Experiencing the world:** Others believe that the meaning of life is simply to experience and appreciate the beauty and wonder of the world around us. This can be done through travel, art, music, nature, or simply taking the time to notice the little things in life.\\n* **Personal growth:** Some people believe that the meaning of life is to grow and develop as a person. This can be achieved through learning new things, challenging ourselves, and overcoming obstacles.\\n* **Connection to something greater:** Many people believe that the meaning of life is to connect with something greater than ourselves, such as a higher power, nature, or the universe. This can be done through meditation, prayer, or simply being present in the moment.\\n\\nNo matter what our beliefs or values, we all have the potential to find meaning and purpose in our lives. By reflecting on our own experiences and values, we can come to a deeper understanding of what makes our lives meaningful.\"\n",
       "  }\n",
       "  role: \"model\"\n",
       "}\n",
       "finish_reason: STOP\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99e23b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gguf_init_from_file: invalid magic characters 'tjgg'\n",
      "llama_model_load: error loading model: llama_model_loader: failed to load model from ./llama-2-7b-chat.ggmlv3.q8_0.bin\n",
      "\n",
      "llama_load_model_from_file: failed to load model\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the large language model file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Llama\n\u001b[0;32m----> 3\u001b[0m LLM \u001b[38;5;241m=\u001b[39m Llama(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./llama-2-7b-chat.ggmlv3.q8_0.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# create a text prompt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: What are the names of the days of the week? A:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/data/ch52669/anaconda3/lib/python3.11/site-packages/llama_cpp/llama.py:314\u001b[0m, in \u001b[0;36mLlama.__init__\u001b[0;34m(self, model_path, n_gpu_layers, split_mode, main_gpu, tensor_split, vocab_only, use_mmap, use_mlock, kv_overrides, seed, n_ctx, n_batch, n_threads, n_threads_batch, rope_scaling_type, rope_freq_base, rope_freq_scale, yarn_ext_factor, yarn_attn_factor, yarn_beta_fast, yarn_beta_slow, yarn_orig_ctx, mul_mat_q, logits_all, embedding, offload_kqv, last_n_tokens_size, lora_base, lora_scale, lora_path, numa, chat_format, chat_handler, draft_model, tokenizer, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mn_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mn_ctx_train()\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mn_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_batch\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx \u001b[38;5;241m=\u001b[39m _LlamaContext(\n\u001b[1;32m    315\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model,\n\u001b[1;32m    316\u001b[0m     params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params,\n\u001b[1;32m    317\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    318\u001b[0m )\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch \u001b[38;5;241m=\u001b[39m _LlamaBatch(\n\u001b[1;32m    321\u001b[0m     n_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_batch,\n\u001b[1;32m    322\u001b[0m     embd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    323\u001b[0m     n_seq_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mn_ctx,\n\u001b[1;32m    324\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    325\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_path:\n",
      "File \u001b[0;32m/data/ch52669/anaconda3/lib/python3.11/site-packages/llama_cpp/_internals.py:252\u001b[0m, in \u001b[0;36m_LlamaContext.__init__\u001b[0;34m(self, model, params, verbose)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llama_free \u001b[38;5;241m=\u001b[39m llama_cpp\u001b[38;5;241m.\u001b[39m_lib\u001b[38;5;241m.\u001b[39mllama_free  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;241m=\u001b[39m llama_cpp\u001b[38;5;241m.\u001b[39mllama_new_context_with_model(\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\n\u001b[1;32m    256\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the large language model file\n",
    "from llama_cpp import Llama\n",
    "LLM = Llama(model_path=\"./llama-2-7b-chat.ggmlv3.q8_0.bin\")\n",
    "\n",
    "# create a text prompt\n",
    "prompt = \"Q: What are the names of the days of the week? A:\"\n",
    "\n",
    "# generate a response (takes several seconds)\n",
    "output = LLM(prompt)\n",
    "\n",
    "# display the response\n",
    "print(output[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e50be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f49751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9082233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: whats your name?\n",
      "A1: ethan\n",
      "A2: aiden\n",
      "A3: anita\n",
      "A4: ethan is \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Q: whats your name?\\nA1: ethan\\nA2: aiden\\nA3: anita\\nA4: ethan is \\nAnswer set at the begining: l'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = 'whats your name?'\n",
    "rewrite_answers = ['ethan', 'aiden', 'anita', 'ethan is ']\n",
    "prompt_q = 'Q: ' + q\n",
    "\n",
    "ans2id = {}\n",
    "cleaned_answers = []\n",
    "for cdt_ans in rewrite_answers:\n",
    "    if cdt_ans.startswith('A: '):\n",
    "        cdt_ans = cdt_ans[len('A: '):]\n",
    "    cleaned_answers.append(cdt_ans)\n",
    "    if cdt_ans not in ans2id: ans2id[cdt_ans] = len(ans2id)\n",
    "\n",
    "for ans_id, cdt_ans in enumerate(list(ans2id.keys())):\n",
    "    prompt_q = prompt_q + f'\\nA{ans_id+1}: ' + cdt_ans\n",
    "print(prompt_q)\n",
    "prev_ans_set='l'\n",
    "prompt_q = prompt_q + f'\\nAnswer set at the begining: {prev_ans_set}'\n",
    "user_prompt = prompt_q\n",
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b41ed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "SapBERT_tokenizer = AutoTokenizer.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n",
    "SapBERT_model = AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d246c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(names):\n",
    "    encoded_input = SapBERT_tokenizer(names, padding=True, truncation=True, return_tensors='pt')\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = SapBERT_model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embedding = model_output.last_hidden_state.mean(dim=1)\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "169fd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ethan', 'anita', 'aiden', 'ethan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e00a8e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3823,  0.1725, -0.1433,  ...,  0.1912,  1.4871, -0.1506],\n",
       "        [-0.2917, -0.7279, -0.2811,  ...,  0.3248,  1.0667,  0.3110],\n",
       "        [-0.7845,  0.0559, -0.0715,  ...,  0.6758, -0.0391, -0.1651],\n",
       "        [ 0.3823,  0.1725, -0.1433,  ...,  0.1912,  1.4871, -0.1506]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = get_emb(names)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe5365b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.4950865 , 0.4311273 , 1.0000002 ],\n",
       "       [0.4950865 , 1.        , 0.41205305, 0.49508664],\n",
       "       [0.4311273 , 0.41205305, 1.0000002 , 0.4311274 ],\n",
       "       [1.0000002 , 0.49508664, 0.4311274 , 1.0000002 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score = cosine_similarity(emb)#[0][0]\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6f0359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999997  0.4949035  0.43019283 0.46856818 0.9999998  0.8340788\n",
      "  0.4264168  0.36038753]\n",
      " [0.4949035  0.9999994  0.4107427  0.4855961  0.4949036  0.42507333\n",
      "  0.4229035  0.37770063]\n",
      " [0.43019283 0.4107427  1.         0.46233964 0.43019277 0.42026806\n",
      "  0.4626209  0.43875158]\n",
      " [0.46856818 0.4855961  0.46233964 1.0000002  0.46856827 0.38939947\n",
      "  0.47662634 0.373399  ]\n",
      " [0.9999998  0.4949036  0.43019277 0.46856827 0.99999964 0.8340788\n",
      "  0.42641678 0.36038762]\n",
      " [0.8340788  0.42507333 0.42026806 0.38939947 0.8340788  1.\n",
      "  0.44818765 0.36909014]\n",
      " [0.4264168  0.4229035  0.4626209  0.47662634 0.42641678 0.44818765\n",
      "  0.99999964 0.5341475 ]\n",
      " [0.36038753 0.37770063 0.43875158 0.373399   0.36038762 0.36909014\n",
      "  0.5341475  0.99999976]]\n",
      "name_frequencies Counter({'ethan': 2, 'anita': 1, 'aiden': 1, 'adam': 1, 'ethan c': 1, 'john': 1, 'jack': 1})\n",
      "Groups based on similarity (>0.98):\n",
      "Group 1: ethan, ethan\n",
      "Group 2: anita\n",
      "Group 3: aiden\n",
      "Group 4: adam\n",
      "Group 5: ethan c\n",
      "Group 6: john\n",
      "Group 7: jack\n",
      "\n",
      "Frequencies of each name:\n",
      "ethan: 2\n",
      "anita: 1\n",
      "aiden: 1\n",
      "adam: 1\n",
      "ethan c: 1\n",
      "john: 1\n",
      "jack: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Given list of names, possibly with duplicates\n",
    "names = ['ethan', 'anita', 'aiden', 'adam', 'ethan', 'ethan c', 'john', 'jack']\n",
    "\n",
    "# Assuming `get_emb` function is defined as before and returns embeddings\n",
    "emb = get_emb(names)\n",
    "similarity_score = cosine_similarity(emb)\n",
    "print(similarity_score)\n",
    "# Threshold for similarity\n",
    "threshold = 0.98\n",
    "\n",
    "# Group names based on similarity\n",
    "groups = []\n",
    "used_indices = set()\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if i in used_indices:\n",
    "        continue\n",
    "    # This name hasn't been grouped yet, so start a new group\n",
    "    current_group = [names[i]]\n",
    "    used_indices.add(i)\n",
    "    for j in range(i + 1, len(names)):\n",
    "        if j in used_indices:\n",
    "            continue\n",
    "        if similarity_score[i, j] > threshold:\n",
    "            current_group.append(names[j])\n",
    "            used_indices.add(j)\n",
    "    groups.append(current_group)\n",
    "\n",
    "    \n",
    "# Calculate frequencies of each original name\n",
    "name_frequencies = Counter(names)\n",
    "print('name_frequencies',name_frequencies)\n",
    "# Print the results\n",
    "print(\"Groups based on similarity (>0.98):\")\n",
    "for i, group in enumerate(groups):\n",
    "    print(f\"Group {i+1}: {', '.join(group)}\")\n",
    "\n",
    "print(\"\\nFrequencies of each name:\")\n",
    "for name, frequency in name_frequencies.items():\n",
    "    print(f\"{name}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9b2a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_forward(q: str, rewrite_answers, prev_ans_set):\n",
    "    prompt_q = 'Q: ' + q\n",
    "\n",
    "    ans2id = {}\n",
    "    cleaned_answers = []\n",
    "    for cdt_ans in rewrite_answers:\n",
    "        if cdt_ans.startswith('A: '):\n",
    "            cdt_ans = cdt_ans[len('A: '):]\n",
    "        cleaned_answers.append(cdt_ans)\n",
    "        if cdt_ans not in ans2id: ans2id[cdt_ans] = len(ans2id)\n",
    "\n",
    "    for ans_id, cdt_ans in enumerate(list(ans2id.keys())):\n",
    "        prompt_q = prompt_q + f'\\nA{ans_id+1}: ' + cdt_ans\n",
    "    prompt_q = prompt_q + f'\\nAnswer set at the begining: {prev_ans_set}'\n",
    "    user_prompt = prompt_q\n",
    "\n",
    "    tokens = tokenizer.tokenize(system_prompt + user_prompt)\n",
    "    print(q)\n",
    "    print(len(tokens))\n",
    "\n",
    "    _max_tokens = 2000\n",
    "    curr_model = \"gpt-3.5-turbo-0613\"\n",
    "    if len(tokens) > 2000:\n",
    "        curr_model = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "\n",
    "    print(f\"Answer set at the begining: {prev_ans_set}\")\n",
    "    print(temperature)\n",
    "    messages = format_message(system_prompt, user_prompt)\n",
    "    response = completion_with_backoff(\n",
    "        model=curr_model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=_max_tokens,\n",
    "        n=1,\n",
    "        )\n",
    "    ans_model = response['choices'][0]['message']['content']\n",
    "    ext_ans, ans_sets = extract_rewrite(ans_model)\n",
    "\n",
    "    if len(ext_ans) != len(ans2id):\n",
    "        print(\"failed!\")\n",
    "        print(ans_model)\n",
    "\n",
    "        return INVLAID_RESUTL, [], prev_ans_set\n",
    "\n",
    "    map_back_list = []\n",
    "    for ans in cleaned_answers:\n",
    "        map_back_list.append(ext_ans[ans2id[ans]])\n",
    "    return SUCCESS, map_back_list, ans_sets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb1357e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_forward(q, rewrite_answers, prev_ans_set)\n",
      "Cell \u001b[0;32mIn[46], line 17\u001b[0m, in \u001b[0;36mbatch_forward\u001b[0;34m(q, rewrite_answers, prev_ans_set)\u001b[0m\n\u001b[1;32m     14\u001b[0m prompt_q \u001b[38;5;241m=\u001b[39m prompt_q \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer set at the begining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprev_ans_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m prompt_q\n\u001b[0;32m---> 17\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(system_prompt \u001b[38;5;241m+\u001b[39m user_prompt)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(q)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tokens))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    " batch_forward(q, rewrite_answers, prev_ans_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d480f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Items based on similarity (>0.98):\n",
      "Index 0: ethan, ethan\n",
      "Index 1: aiden, aiden\n",
      "Index 2: anita, anita, anita\n",
      "Index 4: USA, america\n",
      "\n",
      "Frequencies of each group (by first item):\n",
      "ethan: 0.2222222222222222\n",
      "aiden: 0.2222222222222222\n",
      "anita: 0.3333333333333333\n",
      "USA: 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to compute BERT embeddings\n",
    "def get_bert_embeddings(sentences):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    embeddings = output.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Input list of lists\n",
    "input_lists = [['ethan', 'aiden', 'anita'], ['ethan', 'USA', 'anita'], ['aiden', 'anita', 'america']]\n",
    "\n",
    "# Flatten the list to process all items, including duplicates\n",
    "all_items_flat = [item for sublist in input_lists for item in sublist]\n",
    "\n",
    "# Get embeddings for all items, considering duplicates\n",
    "all_items_embeddings = get_bert_embeddings(all_items_flat)\n",
    "\n",
    "# Calculate cosine similarity between all items\n",
    "similarity_matrix = cosine_similarity(all_items_embeddings)\n",
    "\n",
    "# Threshold for similarity\n",
    "threshold = 0.90\n",
    "\n",
    "# Initialize groups\n",
    "groups = []\n",
    "item_index_group = {}\n",
    "\n",
    "for i in range(len(all_items_flat)):\n",
    "    found_group = False\n",
    "    for group in groups:\n",
    "        if any(similarity_matrix[i, j] > threshold for j in group):\n",
    "            group.append(i)\n",
    "            found_group = True\n",
    "            break\n",
    "    if not found_group:\n",
    "        groups.append([i])\n",
    "\n",
    "# Map group indices back to item names, considering duplicates\n",
    "grouped_items_by_index = defaultdict(list)\n",
    "for group in groups:\n",
    "    # Use the first item in the group as the representative\n",
    "    representative = all_items_flat[group[0]]\n",
    "    for index in group:\n",
    "        grouped_items_by_index[group[0]].append(all_items_flat[index])\n",
    "\n",
    "item_counts = sum([len(group) for group in groups])\n",
    "# Calculate frequencies of groups using the first name in each group as the key\n",
    "group_frequencies = {all_items_flat[group[0]]: len(group)/item_counts for group in groups}\n",
    "\n",
    "# Output results\n",
    "print(\"Grouped Items based on similarity (>0.98):\")\n",
    "for index, items in grouped_items_by_index.items():\n",
    "    print(f\"Index {index}: {', '.join(items)}\")\n",
    "\n",
    "print(\"\\nFrequencies of each group (by first item):\")\n",
    "for item, frequency in group_frequencies.items():\n",
    "    print(f\"{item}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c59a052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.864056  , 0.81072766, 1.0000004 , 0.73723435,\n",
       "        0.8107277 , 0.8640561 , 0.8107277 , 0.79322857],\n",
       "       [0.864056  , 0.99999994, 0.7623788 , 0.864056  , 0.7429619 ,\n",
       "        0.7623787 , 1.0000001 , 0.7623788 , 0.77343696],\n",
       "       [0.81072766, 0.7623788 , 1.0000002 , 0.81072783, 0.77517635,\n",
       "        1.0000001 , 0.7623787 , 1.0000002 , 0.8317076 ],\n",
       "       [1.0000004 , 0.864056  , 0.81072783, 1.0000002 , 0.73723435,\n",
       "        0.8107277 , 0.864056  , 0.8107278 , 0.7932286 ],\n",
       "       [0.73723435, 0.7429619 , 0.77517635, 0.73723435, 0.99999994,\n",
       "        0.77517647, 0.7429619 , 0.7751764 , 0.90159523],\n",
       "       [0.8107277 , 0.7623787 , 1.0000001 , 0.8107277 , 0.77517647,\n",
       "        1.0000002 , 0.7623786 , 1.0000002 , 0.8317077 ],\n",
       "       [0.8640561 , 1.0000001 , 0.7623787 , 0.864056  , 0.7429619 ,\n",
       "        0.7623786 , 1.        , 0.76237863, 0.77343684],\n",
       "       [0.8107277 , 0.7623788 , 1.0000002 , 0.8107278 , 0.7751764 ,\n",
       "        1.0000002 , 0.76237863, 1.0000004 , 0.8317077 ],\n",
       "       [0.79322857, 0.77343696, 0.8317076 , 0.7932286 , 0.90159523,\n",
       "        0.8317077 , 0.77343684, 0.8317077 , 1.0000002 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a32ae9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Top three grouped names based on frequency:\n",
      "3\n",
      "Group 3: anita, anita, anita\n",
      "2\n",
      "Group 1: ethan, ethan\n",
      "2\n",
      "Group 2: aiden, aiden\n",
      "\n",
      "2) Top three frequencies:\n",
      "3\n",
      "2\n",
      "2\n",
      "\n",
      "3) All grouped names and their frequency:\n",
      "Group 3 (anita, anita, anita): 3\n",
      "Group 1 (ethan, ethan): 2\n",
      "Group 2 (aiden, aiden): 2\n",
      "Group 4 (USA): 1\n",
      "Group 5 (america): 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to compute BERT embeddings\n",
    "def get_bert_embeddings(sentences):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    embeddings = output.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "# Input list of lists\n",
    "input_lists = [['ethan', 'aiden', 'anita'], ['ethan', 'USA', 'anita'], ['aiden', 'anita', 'america']]\n",
    "\n",
    "# Flatten the list to process all items, including duplicates\n",
    "all_items_flat = [item for sublist in input_lists for item in sublist]\n",
    "\n",
    "# Get embeddings for all items, considering duplicates\n",
    "all_items_embeddings = get_bert_embeddings(all_items_flat)\n",
    "\n",
    "# Calculate cosine similarity between all items\n",
    "similarity_matrix = cosine_similarity(all_items_embeddings)\n",
    "\n",
    "# Group items based on similarity, considering threshold\n",
    "threshold = 0.98\n",
    "groups = []\n",
    "for i in range(len(all_items_flat)):\n",
    "    grouped = False\n",
    "    for group in groups:\n",
    "        if any(similarity_matrix[i][j] > threshold for j in group):\n",
    "            group.append(i)\n",
    "            grouped = True\n",
    "            break\n",
    "    if not grouped:\n",
    "        groups.append([i])\n",
    "\n",
    "# Calculate group frequencies\n",
    "group_frequencies = {i: len(group) for i, group in enumerate(groups)}\n",
    "\n",
    "# Sort groups by frequency\n",
    "sorted_group_freq = sorted(group_frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select top 3 groups\n",
    "top_3_groups = sorted_group_freq[:3]\n",
    "\n",
    "# Display top 3 grouped names and frequencies\n",
    "print(\"1) Top three grouped names based on frequency:\")\n",
    "for index, f in top_3_groups:\n",
    "    print(f\"Group {index + 1}: {', '.join(all_items_flat[i] for i in groups[index])}\")\n",
    "\n",
    "print(\"\\n2) Top three frequencies:\")\n",
    "for _, freq in top_3_groups:\n",
    "    print(freq)\n",
    "\n",
    "# Display all grouped names and their frequencies\n",
    "print(\"\\n3) All grouped names and their frequency:\")\n",
    "for index, freq in sorted_group_freq:\n",
    "    print(f\"Group {index + 1} ({', '.join(all_items_flat[i] for i in groups[index])}): {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25e52940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "array1 = np.array([0, 1, 1])\n",
    "array2 = np.array([1, 2, 3])\n",
    "\n",
    "# Element-wise multiplication\n",
    "result = array1 * array2\n",
    "print(result.tolist())  # Output: [0 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7726f8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 2, 'd', 4]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_list = [[1,2,3], [2,'d',4]]\n",
    "ys = [item  for items in ys_list for item in items]\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ids = sorted(ids, key=lambda x: values[x], reverse=True)[:args.n_select_sample]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
